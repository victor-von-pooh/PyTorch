{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conf.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLy1_KRgAnP_"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece] seqeval sacrebleu huggingface_hub accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "from huggingface_hub import notebook_login\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "x3puwREZBAZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang1, lang2 = \"en\", \"ja\"\n",
        "raw_datasets = load_dataset(\"kde4\", lang1=lang1, lang2=lang2)\n",
        "split_datasets = raw_datasets[\"train\"].train_test_split(train_size=0.9, seed=8192)\n",
        "split_datasets[\"validation\"] = split_datasets.pop(\"test\")"
      ],
      "metadata": {
        "id": "yApbYhNDBSKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(split_datasets)"
      ],
      "metadata": {
        "id": "cRDbH2b_BXGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  print(split_datasets[\"train\"][i])"
      ],
      "metadata": {
        "id": "msIeMEHuBg1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"Helsinki-NLP/opus-tatoeba-en-ja\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "4LHSP3R5CB9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = [ex[lang1] for ex in examples[\"translation\"]]\n",
        "    targets = [ex[lang2] for ex in examples[\"translation\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=128, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    \n",
        "    return model_inputs\n",
        "\n",
        "tokenized_datasets = split_datasets.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=split_datasets[\"train\"].column_names,\n",
        ")"
      ],
      "metadata": {
        "id": "hbjBBD7XCGMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_datasets)"
      ],
      "metadata": {
        "id": "uIkXtZBpCtIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  print(tokenized_datasets[\"train\"][i])"
      ],
      "metadata": {
        "id": "tRee3XhmCG1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "MblDRvdto5h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"sacrebleu\")"
      ],
      "metadata": {
        "id": "wTbJnXxHo9Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"marian-finetuned-kde4-en-to-ja\",\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=3,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "h63ranLco_rU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "xUKVdvPtpCV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "H9bKnIEYpFAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(max_length=128)"
      ],
      "metadata": {
        "id": "_VjCXkFtpG7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(tags=\"translation\", commit_message=\"Training complete\")"
      ],
      "metadata": {
        "id": "U3yVmB38pI2h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}